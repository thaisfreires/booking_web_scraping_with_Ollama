# Web Scraping Wikipedia with Ollama


Easily scrape data from Wikipedia and use Ollama AI to generate smart, context-aware responses. This simple setup leverages document retrieval and AI-powered generation to create dynamic conversations from live web content.
## About

ğŸ“š Smart Document Retrieval

Your chatbot gets smarter with document retrieval! By using Chromaâ€™s powerful vector database, it can pull the most relevant information from your knowledge base to make sure its answers are accurate and to the point.

ğŸ¤– AI-Powered Conversations

Leverage the power of cutting-edge models like ChatOllama to generate insightful responses. The LLM seamlessly combines retrieved documents and user queries, delivering responses that are both relevant and highly personalized.

ğŸ› ï¸ Always Up-to-Date Knowledge

Maintain and expand your systemâ€™s knowledge base with Chromaâ€™s persistent storage. The system allows dynamic updates to document embeddings, ensuring your knowledge is always up-to-date and readily accessible.
## Installation

1. Clone the repository

```bash
 git clone https://github.com/thaisfreires/web_scraping_with_Ollama.git
```
2. Create the virtual environment variables
```bash
py -m venv .venv
```
3. Activate the virtual environment
```bash
.venv\Scripts\activate
```
4. Run the file requirements.txt to dependency tools
```bash
pip install -r requirements.txt
``` 